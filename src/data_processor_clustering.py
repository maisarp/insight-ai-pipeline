import pandas as pd
import numpy as np
import os
import sys
import io
from typing import List, Dict, Tuple, Optional
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

# Configura o encoding para UTF-8 no Windows
if sys.platform.startswith('win'):
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')


class DataProcessorClustering:
    """
    Processador de dados otimizado para clustering com valida√ß√£o robusta.
    
    Atributos:
        file_path (str): Caminho do arquivo de dados.
        dataframe (pd.DataFrame): Dados carregados.
        required_columns (list): Colunas obrigat√≥rias para an√°lise.
        processed_data (pd.DataFrame): Dados processados para clustering.
        scaler (StandardScaler): Normalizador de dados.
    """
    
    # Colunas obrigat√≥rias para an√°lise
    REQUIRED_COLUMNS = [
        'G√™nero',
        'Idade',
        'Estado civil',
        'Bolsa Fam√≠lia',
        'Grau de escolaridade',
        'Situa√ß√£o escolar',
        'Situa√ß√£o de Trabalho',
        'Remunera√ß√£o',
        'Procurando trabalho',
        'Faz ou fez uso de drogas',
        'Data de Cadastro'
    ]
    
    # Colunas identificadoras esperadas (pelo menos uma deve existir e ter dados)
    IDENTIFIER_COLUMNS = [
        'Nome completo',
        'Nome',
        'CPF',
        'RG',
        'ID',
        'Identificador',
        'Matr√≠cula'
    ]
    
    # Mapeamentos para encoding
    EDUCATION_BASE_MAP = {
        # Sem escolaridade
        '': 0,
        'sem escolaridade': 0,
        'sem escolaridade - nao alfabetizado': 0,
        'educacao infantil - educacao infantil': 0,
        'educacao infantil': 0,
        # Ensino fundamental
        'sem escolaridade - ensino tecnico': 1,
        'educacao de jovens e adultos (eja) - ensino fundamental (eja)': 1,
        'ensino fundamental - 1 ano': 1,
        'ensino fundamental - 3 ano': 1,
        'ensino fundamental - 4 ano': 1,
        'ensino fundamental - 5 ano': 1,
        'ensino fundamental - 6 ano': 1,
        'ensino fundamental - 7 ano': 1,
        'ensino fundamental - 8 ano': 1,
        'ensino fundamental - 9 ano': 1,
        # Ensino m√©dio
        'ensino medio - 1 ano': 2,
        'ensino medio - 2 ano': 2,
        'ensino medio - 3 ano': 2,
        'ensino medio': 2,
        # Ensino superior
        'ensino superior - graduacao': 3,
        'ensino superior': 3
    }
    
    def __init__(self, file_path: str, verbose: bool = True):
        """
        Inicializa o processador.
        
        Args:
            file_path (str): Caminho do arquivo Excel ou CSV.
        """
        self.file_path = file_path
        self.dataframe = None
        self.processed_data = None
        self.scaler = StandardScaler()
        self.feature_names = []
        self.missing_columns = []
        self.verbose = verbose
        
        # Peso reduzido para a vari√°vel de depend√™ncia qu√≠mica
        self.feature_weights = {
            'substance_dependency': 0.5,  # Peso reduzido para depend√™ncia qu√≠mica
            'age': 1.0,
            'education_level': 1.0,
            'family_benefit': 1.0,
            'studying': 1.0,
            'looking_for_job': 1.0,
            'employment_signal': 0.4,
            'program_duration': 1.0,
            'marital_status_single': 1.0,
            'marital_status_married': 1.0,
            'income': 1.0
        }

    def _print(self, message: str, force: bool = False) -> None:
        """Exibe mensagens condicionadas √† configura√ß√£o de verbosidade."""
        if self.verbose or force:
            print(message)
    
    def _has_meaningful_data(self, dataframe: pd.DataFrame) -> bool:
        """
        Verifica se o dataframe cont√©m dados significativos.
        
        Args:
            dataframe (pd.DataFrame): DataFrame a ser validado.
        
        Returns:
            bool: True se h√° pelo menos uma c√©lula com dado significativo.
        """
        if dataframe.empty:
            return False
        
        # Remove linhas completamente vazias
        df_no_empty_rows = dataframe.dropna(how='all')
        
        if df_no_empty_rows.empty:
            return False
        
        # Verifica se existe pelo menos uma c√©lula com dado n√£o-vazio e n√£o-nan
        for col in df_no_empty_rows.columns:
            for value in df_no_empty_rows[col]:
                # Ignora NaN/None
                if pd.isna(value):
                    continue
                # Converte para string e verifica se n√£o est√° vazio
                str_value = str(value).strip()
                if str_value and str_value.lower() not in {'nan', 'none', ''}:
                    return True
        
        return False
    
    def _build_missing_columns_error(self, missing_columns: List[str]) -> str:
        """
        Constr√≥i mensagem de erro formatada para colunas faltantes.
        
        Args:
            missing_columns: Lista de nomes de colunas faltantes.
            
        Returns:
            str: Mensagem de erro formatada.
        """
        all_required = [
            "‚Ä¢ G√™nero",
            "‚Ä¢ Idade", 
            "‚Ä¢ Estado civil",
            "‚Ä¢ Bolsa Fam√≠lia",
            "‚Ä¢ Grau de escolaridade",
            "‚Ä¢ Situa√ß√£o escolar",
            "‚Ä¢ Situa√ß√£o de Trabalho",
            "‚Ä¢ Remunera√ß√£o",
            "‚Ä¢ Procurando trabalho",
            "‚Ä¢ Faz ou fez uso de drogas",
            "‚Ä¢ Data de Cadastro"
        ]
        
        return (
            f"\n{'='*80}\n"
            f"‚ùå ERRO: O arquivo n√£o possui todas as colunas necess√°rias\n"
            f"{'='*80}\n\n"
            f"Coluna(s) faltando no seu arquivo:\n" +
            "\n".join([f"  ‚úó {col}" for col in missing_columns]) +
            f"\n\n{'‚îÄ'*80}\n\n"
            f"üìã COLUNAS OBRIGAT√ìRIAS (todas devem estar presentes):\n\n" +
            "\n".join([f"  {col}" for col in all_required]) +
            f"\n\n{'‚îÄ'*80}\n\n"
            f"üí° DICA: Verifique se sua planilha possui EXATAMENTE esses nomes de colunas.\n"
            f"   Os nomes devem ser id√™nticos, incluindo acentos e espa√ßos.\n\n"
            f"{'='*80}\n"
        )
    
    def load_data(self) -> 'DataProcessorClustering':
        """
        Carrega dados do arquivo.
        
        Returns:
            self: Para encadeamento de m√©todos.
        
        Raises:
            FileNotFoundError: Se arquivo n√£o existe.
            ValueError: Se formato n√£o suportado.
        """
        if not os.path.exists(self.file_path):
            raise FileNotFoundError(f"Arquivo n√£o encontrado: {self.file_path}")
        
        lower = self.file_path.lower()
        
        try:
            if lower.endswith('.csv'):
                # Tenta diferentes encodings e delimitadores para CSV
                encodings = ['utf-8-sig', 'latin-1', 'iso-8859-1', 'cp1252']
                delimiters = [',', ';', '\t']
                self.dataframe = None
                last_error = None
                
                for encoding in encodings:
                    for delimiter in delimiters:
                        try:
                            df = pd.read_csv(
                                self.file_path, 
                                encoding=encoding, 
                                delimiter=delimiter,
                                on_bad_lines='skip'  # Pula linhas problem√°ticas
                            )
                            # Verifica se o CSV foi lido corretamente (tem mais de 1 coluna)
                            if not df.empty and len(df.columns) > 1:
                                self.dataframe = df
                                self._print(f"[OK] CSV carregado com encoding: {encoding}, delimitador: '{delimiter}'")
                                break
                        except Exception as e:
                            last_error = e
                            continue
                    
                    if self.dataframe is not None:
                        break
                
                if self.dataframe is None:
                    raise RuntimeError(
                        f"N√£o foi poss√≠vel ler o CSV com nenhuma combina√ß√£o de encoding/delimitador. "
                        f"√öltimo erro: {last_error}"
                    )
            
            # Valida se o CSV tem dados significativos
            if not self._has_meaningful_data(self.dataframe):
                raise ValueError(
                    "O arquivo n√£o cont√©m dados v√°lidos para an√°lise. "
                    "Todas as linhas est√£o vazias ou n√£o possuem informa√ß√µes significativas."
                )
                    
            elif lower.endswith(('.xlsx', '.xls')):
                # Para arquivos Excel, usa engine openpyxl que lida melhor com encoding
                try:
                    self.dataframe = pd.read_excel(self.file_path, engine='openpyxl')
                except Exception:
                    # Fallback para engine padr√£o
                    self.dataframe = pd.read_excel(self.file_path)
                
                # Valida se o Excel tem dados significativos
                if not self._has_meaningful_data(self.dataframe):
                    raise ValueError(
                        "O arquivo n√£o cont√©m dados v√°lidos para an√°lise. "
                        "Todas as linhas est√£o vazias ou n√£o possuem informa√ß√µes significativas."
                    )
            else:
                raise ValueError('Formato n√£o suportado. Use .xlsx, .xls ou .csv')
            
            self._print(f"[OK] Dados carregados: {len(self.dataframe)} registros, {len(self.dataframe.columns)} colunas")
            return self
            
        except Exception as e:
            raise RuntimeError(f"Erro ao carregar arquivo: {str(e)}")
    
    def validate_columns(self, strict: bool = False) -> Tuple[bool, List[str]]:
        """
        Valida se as colunas obrigat√≥rias est√£o presentes.
        
        Args:
            strict (bool): Se True, lan√ßa exce√ß√£o. Se False, apenas avisa.
        
        Returns:
            tuple: (is_valid, missing_columns)
        
        Raises:
            ValueError: Se strict=True e colunas faltando.
        """
        if self.dataframe is None:
            raise RuntimeError("Dados n√£o carregados. Execute load_data() primeiro.")
        
        # Normaliza nomes das colunas do arquivo
        df_columns_normalized = [col.strip().lower() for col in self.dataframe.columns]
        required_normalized = [col.strip().lower() for col in self.REQUIRED_COLUMNS]
        
        # Identifica colunas faltando
        self.missing_columns = []
        for req_col in self.REQUIRED_COLUMNS:
            req_normalized = req_col.strip().lower()
            if req_normalized not in df_columns_normalized:
                self.missing_columns.append(req_col)
        
        if self.missing_columns:
            if strict:
                # Usa m√©todo centralizado para construir mensagem de erro
                error_msg = self._build_missing_columns_error(self.missing_columns)
                raise ValueError(error_msg)
            else:
                # Modo n√£o-strict: aviso simples
                self._print(f"\n‚ö† Aten√ß√£o: Algumas colunas obrigat√≥rias est√£o faltando:", force=True)
                for col in self.missing_columns:
                    self._print(f"  ‚úó {col}", force=True)
                self._print("\nüí° O sistema tentar√° continuar, mas a qualidade da an√°lise pode ser afetada.", force=True)
                self._print("   Recomendamos usar um arquivo com todas as colunas obrigat√≥rias.\n", force=True)
                return False, self.missing_columns

        self._print("‚úì Todas as colunas obrigat√≥rias est√£o presentes")
        return True, []
    
    def validate_identifier_columns(self) -> Tuple[bool, Optional[str]]:
        """
        Valida se existe pelo menos uma coluna identificadora com dados v√°lidos.
        
        Returns:
            tuple: (is_valid, identifier_found or error_message)
        
        Raises:
            ValueError: Se nenhuma coluna identificadora v√°lida for encontrada.
        """
        if self.dataframe is None:
            raise RuntimeError("Dados n√£o carregados. Execute load_data() primeiro.")
        
        # Normaliza nomes das colunas do arquivo
        df_columns_normalized = {col.strip().lower(): col for col in self.dataframe.columns}
        
        # Procura por colunas identificadoras
        found_identifiers = []
        for id_col in self.IDENTIFIER_COLUMNS:
            id_normalized = id_col.strip().lower()
            if id_normalized in df_columns_normalized:
                original_col_name = df_columns_normalized[id_normalized]
                
                # Verifica se a coluna tem pelo menos um valor n√£o-vazio
                has_data = False
                for value in self.dataframe[original_col_name]:
                    if pd.notna(value) and str(value).strip():
                        str_val = str(value).strip().lower()
                        if str_val not in {'nan', 'none', ''}:
                            has_data = True
                            break
                
                if has_data:
                    found_identifiers.append(original_col_name)
        
        if not found_identifiers:
            # Constr√≥i mensagem de erro detalhada
            error_msg = (
                f"\n{'='*80}\n"
                f"‚ùå ERRO: Nenhuma coluna identificadora v√°lida encontrada\n"
                f"{'='*80}\n\n"
                f"Para realizar a an√°lise, √© necess√°rio ter pelo menos UMA coluna\n"
                f"identificadora com dados v√°lidos (n√£o-vazios).\n\n"
                f"{'‚îÄ'*80}\n\n"
                f"üìã COLUNAS IDENTIFICADORAS ACEITAS (pelo menos uma deve existir):\n\n" +
                "\n".join([f"  ‚Ä¢ {col}" for col in self.IDENTIFIER_COLUMNS]) +
                f"\n\n{'‚îÄ'*80}\n\n"
                f"üí° DICAS:\n"
                f"   1. Adicione uma coluna com nome, CPF, RG ou outro identificador\n"
                f"   2. Verifique se a coluna identificadora n√£o est√° vazia\n"
                f"   3. Os nomes devem ser id√™nticos aos listados acima\n\n"
                f"{'='*80}\n"
            )
            raise ValueError(error_msg)
        
        self._print(f"‚úì Coluna(s) identificadora(s) encontrada(s): {', '.join(found_identifiers)}")
        return True, found_identifiers[0]
    
    def normalize_text(self, text: str) -> str:
        """
        Normaliza texto para matching robusto.
        
        Args:
            text (str): Texto a normalizar.
        
        Returns:
            str: Texto normalizado.
        """
        if pd.isna(text) or text == '':
            return ''
        
        text = str(text).strip().lower()
        # Remove acentos comuns
        replacements = {
            '√°': 'a', '√†': 'a', '√£': 'a', '√¢': 'a',
            '√©': 'e', '√™': 'e',
            '√≠': 'i',
            '√≥': 'o', '√¥': 'o', '√µ': 'o',
            '√∫': 'u', '√º': 'u',
            '√ß': 'c'
        }
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        return text
    
    def encode_escolaridade(self, value: str) -> int:
        """
        Codifica grau de escolaridade em valor ordinal simplificado.
        
        Args:
            value (str): Grau de escolaridade informado.
        
        Returns:
            int: C√≥digo ordinal (0=Sem escolaridade, 1=Fundamental,
                 2=M√©dio, 3=Superior).
        """
        if pd.isna(value) or not str(value).strip():
            return 0
        
        normalized = self.normalize_text(value)
        if normalized in self.EDUCATION_BASE_MAP:
            return self.EDUCATION_BASE_MAP[normalized]
        
        # Ajuste para valores com s√≠mbolos como "¬∫" ou varia√ß√µes de acento
        normalized = normalized.replace('¬∫', '').replace('¬∞', '')
        if normalized in self.EDUCATION_BASE_MAP:
            return self.EDUCATION_BASE_MAP[normalized]
        
        # Busca parcial por palavras-chave
        if 'superior' in normalized or 'graduacao' in normalized or 'graduacao' in normalized:
            return 3
        if 'medio' in normalized:
            return 2
        if 'fundamental' in normalized or 'tecnico' in normalized or 'eja' in normalized:
            return 1

        self._print(f"‚ö† Valor n√£o reconhecido na coluna 'Grau de escolaridade': '{value}' (usando valor padr√£o: sem escolaridade)", force=True)
        return 0
    
    def parse_binary(self, value) -> int:
        """
        Converte valores diversos para bin√°rio (0/1).
        
        Args:
            value: Valor a converter.
        
        Returns:
            int: 0 ou 1.
        """
        if pd.isna(value) or not str(value).strip():
            return 0
            
        normalized = str(value).lower().strip()
        normalized = normalized.replace('\xa0', ' ')
        normalized = ' '.join(normalized.split())

        # Mapeia varia√ß√µes de sim/n√£o para 1/0
        if normalized in ['sim', 's', '1', 'true', 'verdadeiro', 'yes', 'y', 'sim - r$ 600,00', 'sim - r$ 300,00']:
            return 1
        elif normalized in ['n√£o', 'nao', 'n', '0', 'false', 'falso', 'no', '']:
            return 0

        if 'sim' in normalized:
            return 1
        if 'n√£o' in normalized or 'nao' in normalized:
            return 0
            
        # Se n√£o for nenhum dos valores conhecidos, assume que √© n√£o
        return 0
    
    def parse_remuneracao(self, value) -> float:
        """
        Extrai valor num√©rico de remunera√ß√£o.
        
        Args:
            value: Valor a converter.
        
        Returns:
            float: Valor num√©rico.
        """
        if pd.isna(value) or not str(value).strip():
            return 0.0
            
        # Remove formata√ß√£o brasileira
        cleaned_text = str(value).strip()
        cleaned_text = cleaned_text.replace('R$', '').replace('r$', '').replace(' ', '')
        cleaned_text = cleaned_text.replace('.', '').replace(',', '.').strip()
        
        try:
            return float(cleaned_text)
        except:
            self._print(f"‚ö† Valor n√£o reconhecido na coluna 'Remunera√ß√£o': '{value}' (usando valor padr√£o: R$ 0,00)", force=True)
            return 0.0
    
    def prepare_features_for_clustering(self) -> pd.DataFrame:
        """
        Prepara features otimizadas para clustering.
        
        Returns:
            pd.DataFrame: Dados processados e normalizados.
        """
        if self.dataframe is None:
            raise RuntimeError("Dados n√£o carregados. Execute load_data() primeiro.")

        self._print("\nüìä Preparando dados para an√°lise...")
        
        df = self.dataframe.copy()
        features = {}
        
        # Normaliza nomes das colunas
        df.columns = [col.strip() for col in df.columns]
        
        # 1. Idade (num√©rico)
        if 'Idade' in df.columns:
            # Converte para num√©rico, tratando valores inv√°lidos
            features['age'] = pd.to_numeric(df['Idade'], errors='coerce').fillna(0)
        
        # 2. Estado civil (one-hot para os principais)
        if 'Estado civil' in df.columns:
            civil_status = df['Estado civil'].apply(
                lambda value: '' if pd.isna(value) else ' '.join(str(value).strip().lower().split())
            )

            single_options = {'solteiro(a)', 'solteiro', 'solteira'}
            married_options = {
                'casado(a)',
                'casado',
                'casada',
                'uni√£o est√°vel',
                'uniao estavel',
            }

            features['marital_status_single'] = civil_status.isin(single_options).astype(int)
            features['marital_status_married'] = civil_status.isin(married_options).astype(int)
        
        # 3. Benef√≠cio social (bin√°rio)
        if 'Bolsa Fam√≠lia' in df.columns:
            features['family_benefit'] = df['Bolsa Fam√≠lia'].apply(self.parse_binary)
        
        # 4. N√≠vel educacional (ordinal)
        if 'Grau de escolaridade' in df.columns:
            features['education_level'] = df['Grau de escolaridade'].apply(self.encode_escolaridade)
        
        # 5. Situa√ß√£o educacional (bin√°rio: estudando ou n√£o)
        if 'Situa√ß√£o escolar' in df.columns:
            # Mapeia para valores bin√°rios
            education_status_map = {
                'cursando': 1,  # Considera como estudando
                'interrompido': 0,
                'conclu√≠do': 0,
                'concluido': 0,
                '': 0  # Considera vazio como n√£o estudando
            }
            
            # Aplica o mapeamento, convertendo para min√∫sculas e removendo espa√ßos extras
            school_status = df['Situa√ß√£o escolar'].astype(str).str.strip().str.lower().fillna('')
            features['studying'] = school_status.map(lambda x: education_status_map.get(x, 0))

        # 6. Situa√ß√£o de trabalho (escala 0 a 1)
        if 'Situa√ß√£o de Trabalho' in df.columns:
            work_status = df['Situa√ß√£o de Trabalho'].astype(str).str.strip().str.lower().fillna('')
            work_status = work_status.replace({'n√£o informado': '', 'nao informado': ''})

            unemployed_options = {
                'desempregado',
                'desempregado(a)',
                'desempregado (a)',
                'sem emprego',
                'sem trabalho',
                'dona de casa',
                ''
            }

            informal_options = {
                'trabalhador por conta propria (bico, autonomo)',
                'trabalhador por conta propria',
                'trabalhador informal',
                'autonomo',
                'aut√¥nomo',
                'empregado sem carteira de trabalho assinada',
                'trabalhador por conta proÃÅpria',
                'bico'
            }

            formal_options = {
                'empregado com carteira de trabalho assinada',
                'empregado com carteira assinada',
                'empregado clt',
                'clt',
                'aprendiz',
                'estagiario',
                'estagi√°rio'
            }

            def map_employment(value: str) -> float:
                """Mapeia situa√ß√£o de trabalho para escala de 0 a 1."""
                if value in formal_options:
                    return 1.0
                if value in informal_options:
                    return 0.6
                if value in unemployed_options:
                    return 0.0
                return 0.0

            features['employment_signal'] = work_status.map(map_employment).fillna(0.0)

        # 7. Renda (num√©rico)
        if 'Remunera√ß√£o' in df.columns:
            features['income'] = df['Remunera√ß√£o'].apply(self.parse_remuneracao)

        # 8. Busca por emprego (bin√°rio)
        if 'Procurando trabalho' in df.columns:
            features['looking_for_job'] = df['Procurando trabalho'].apply(self.parse_binary)

        # 9. Depend√™ncia qu√≠mica (bin√°rio com terminologia adequada)
        if 'Faz ou fez uso de drogas' in df.columns:
            def parse_substance_dependency(value):
                """
                Identifica se h√° depend√™ncia qu√≠mica com base no uso de subst√¢ncias.
                
                Args:
                    value: Valor da coluna 'Faz ou fez uso de drogas'
                    
                Returns:
                    int: 1 se houver evid√™ncia de depend√™ncia, 0 caso contr√°rio
                """
                if pd.isna(value) or not str(value).strip() or str(value).strip().lower() == 'n√£o possui':
                    return 0
                # Considera como dependente se houver qualquer men√ß√£o a drogas
                return 1
                
            features['substance_dependency'] = df['Faz ou fez uso de drogas'].astype(str).apply(parse_substance_dependency)

        # 10. Tempo no programa (em meses) - calculado a partir da Data de Cadastro
        if 'Data de Cadastro' in df.columns:
            from datetime import datetime
            
            # Converte para datetime (formato brasileiro: DD/MM/YYYY)
            registration_dates = pd.to_datetime(df['Data de Cadastro'], format='%d/%m/%Y', errors='coerce')
            
            # Calcula diferen√ßa em dias
            today = datetime.now()
            days_in_program = (today - registration_dates).dt.days
            
            # Converte para meses (arredonda para 1 casa decimal)
            features['program_duration'] = (days_in_program / 30.0).round(1).fillna(0)

            self._print(
                f"  ‚úì Coluna 'Data de Cadastro' processada: tempo m√≠nimo={features['program_duration'].min():.1f} meses, "
                f"tempo m√°ximo={features['program_duration'].max():.1f} meses, "
                f"tempo m√©dio={features['program_duration'].mean():.1f} meses"
            )
        
        # Cria DataFrame
        self.processed_data = pd.DataFrame(features)
        self.feature_names = list(features.keys())

        self._print(f"\n‚úì Dados preparados com sucesso!")
        self._print(f"  ‚Ä¢ Total de registros processados: {len(self.processed_data)}")
        self._print(f"  ‚Ä¢ Total de caracter√≠sticas analisadas: {len(self.feature_names)}")

        return self.processed_data
    
    def normalize_features(self, fit: bool = True) -> np.ndarray:
        """
        Normaliza features usando StandardScaler, aplicando pesos espec√≠ficos.
        
        Args:
            fit (bool): Se True, ajusta o scaler. Se False, apenas transforma.
        
        Returns:
            np.ndarray: Dados normalizados e ponderados.
        """
        if self.processed_data is None:
            raise RuntimeError("Features n√£o preparadas. Execute prepare_features_for_clustering() primeiro.")
        
        # Valida features esperadas vs presentes (apenas quando N√ÉO est√° ajustando)
        if not fit and hasattr(self.scaler, 'feature_names_in_'):
            expected_features = set(self.scaler.feature_names_in_)
            current_features = set(self.processed_data.columns)
            
            missing = expected_features - current_features
            if missing:
                # Mapeia nomes t√©cnicos para nomes de colunas
                feature_map = {
                    'age': 'Idade',
                    'marital_status_single': 'Estado civil',
                    'marital_status_married': 'Estado civil',
                    'family_benefit': 'Bolsa Fam√≠lia',
                    'education_level': 'Grau de escolaridade',
                    'studying': 'Situa√ß√£o escolar',
                    'employment_signal': 'Situa√ß√£o de Trabalho',
                    'income': 'Remunera√ß√£o',
                    'looking_for_job': 'Procurando trabalho',
                    'substance_dependency': 'Faz ou fez uso de drogas',
                    'program_duration': 'Data de Cadastro'
                }
                
                missing_readable = []
                for feat in missing:
                    readable_name = feature_map.get(feat, feat)
                    if readable_name not in missing_readable:  # Evita duplicatas
                        missing_readable.append(readable_name)
                
                # Reutiliza o m√©todo centralizado para construir a mensagem
                error_msg = self._build_missing_columns_error(missing_readable)
                raise ValueError(error_msg)
        
        # Aplica pesos √†s features
        weighted_data = self.processed_data.copy()
        for feature in self.processed_data.columns:
            weight = self.feature_weights.get(feature, 1.0)
            weighted_data[feature] = self.processed_data[feature] * weight
        
        # Aplica a normaliza√ß√£o
        if fit:
            normalized = self.scaler.fit_transform(weighted_data)
            self._print("‚úì Dados normalizados e ponderados com sucesso (ajuste inicial)")
        else:
            normalized = self.scaler.transform(weighted_data)
            self._print("‚úì Dados normalizados usando padr√£o do treinamento")
        
        return normalized
    
    def get_feature_summary(self) -> Dict:
        """
        Retorna resumo estat√≠stico das features.
        
        Returns:
            dict: Estat√≠sticas descritivas.
        """
        if self.processed_data is None:
            raise RuntimeError("Features n√£o preparadas.")
        
        return {
            'total_registros': len(self.processed_data),
            'total_features': len(self.feature_names),
            'features': self.feature_names,
            'estatisticas': self.processed_data.describe().to_dict(),
            'valores_faltando': self.processed_data.isnull().sum().to_dict()
        }


# ---
# Nota de Transpar√™ncia e Responsabilidade
#
# Descri√ß√£o: Este arquivo cont√©m se√ß√µes de c√≥digo que foram geradas
#            ou assistidas por IA.
#
# Auditoria: Todo o c√≥digo foi revisado, testado e validado por
#            uma desenvolvedora humana.
#
# Tag:       @ai_generated
# Dev:       Maisa Pires
# ---
